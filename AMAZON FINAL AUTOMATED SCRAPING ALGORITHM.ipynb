{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMAZON FINAL AUTOMATED SCRAPING ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Required Liabraries\n",
    "import re\n",
    "import csv \n",
    "import requests\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "from msedge.selenium_tools import Edge, EdgeOptions\n",
    "\n",
    "#user defined function for accessing the product review page number URL and automating the page movement for fetchng the reviews\n",
    "def get_url(link):\n",
    "    template = link\n",
    "    #add term query to url\n",
    "    url = template.format(link)\n",
    "    \n",
    "    #add page query placeholder\n",
    "    url += '&pageNumber={}'\n",
    "    return url\n",
    "\n",
    "\n",
    "#user defined function for extractig target data from the Amazon review webpage\n",
    "def extract_record(item):\n",
    "    \"\"\"Extract and Return data from a single record\"\"\"\n",
    "    \n",
    "    ##Reviewer Name\n",
    "    names = item.find('span', {'class':'a-profile-name'}).text\n",
    "    \n",
    "    try:\n",
    "        #Review Title\n",
    "        title = item.find('a', {'class':'review-title-content'}).text.strip()\n",
    "        review_title =title.lstrip('\\n')\n",
    "        review_title =title.rstrip('\\n')\n",
    "    except AttributeError:\n",
    "        title = ''\n",
    "        \n",
    "\n",
    "    try:\n",
    "        #Review date\n",
    "        review_date = item.find('span', {'data-hook':'review-date'}).text[20:].strip()\n",
    "    except AttributeError:\n",
    "        review_date = ''\n",
    "        \n",
    "\n",
    "    try:\n",
    "        #Rating \n",
    "        rating = item.find('i', {'class':'review-rating'}).text\n",
    "        rating_received = rating[0:3]\n",
    "        total_rating = rating[11]\n",
    "    except AttributeError:\n",
    "        rating_received = ''\n",
    "        total_rating = ''\n",
    "        \n",
    "    try:\n",
    "        #Review Content \n",
    "        review = item.find('span', {'data-hook' : 'review-body'}).text.strip('\\n ')\n",
    "        #pattern = 'Your browser does not support HTML5 video'\n",
    "        reviews = re.sub(r\"Your browser does not support HTML5 video.\\n\\n\\n  \\xa0\", \"\",review)\n",
    "    except AttributeError:\n",
    "        reviews = ''\n",
    "              \n",
    "    try:\n",
    "        #user help\n",
    "        user_help = item.find('span', {'data-hook':'helpful-vote-statement'}).text.strip()\n",
    "        if user_help == 'One person found this helpful':\n",
    "            user_help = '1 person found this helpful'\n",
    "        help_vote = int(user_help.split()[0])\n",
    "    except AttributeError:\n",
    "        help_vote = '0'\n",
    "        \n",
    "    result = (names, review_title,review_date, rating_received,total_rating, reviews,help_vote)\n",
    "    return result\n",
    "\n",
    "#user defined main function for performing web scraping of reviews from the amazon webpage\n",
    "def main(link):\n",
    "    \"\"\"Run Main Program Routine\"\"\"\n",
    "    webdriver_location = \"C:/Users/sarth/.wdm/drivers/edgedriver/win64/89.0.774.68/msedgedriver.exe\"\n",
    "    options = EdgeOptions()\n",
    "    options.use_chromium = True\n",
    "    driver = Edge(options=options, executable_path=webdriver_location)\n",
    "\n",
    "    records = []\n",
    "    url = get_url(link)\n",
    "    \n",
    "    #loop for getting the url of next review page along with accessing that page using beautiful soup\n",
    "    for page in range(1,4):\n",
    "        driver.get(url.format(page))\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        results = soup.find_all('div', {'class' : 'a-section celwidget'})\n",
    "    \n",
    "    #creating a loop for extracting the target data from each of the user review card\n",
    "        for item in results:\n",
    "            record = extract_record(item)\n",
    "            if record:\n",
    "                 records.append(record)\n",
    "    \n",
    "    driver.close()\n",
    "    \n",
    "            #save data to csv file\n",
    "    with open('IACI18X95T3C_Amazon.csv','w', newline='',encoding = 'utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Reviewer Name','Review Title','Review Date', 'Rating Received','Total Rating', 'Review_Content', 'Helpful vote statement'])\n",
    "        writer.writerows(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the main function with passing the link of first review page for a product\n",
    "main('https://www.amazon.in/IFB-Inverter-Split-Copper-IACI18X95T3C/product-reviews/B07PNNWTMJ/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
